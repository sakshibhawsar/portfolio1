<html>
<head>
     <title>Data Structures</title>
    <body>
 <h1>Data Structure</h1>
      <h3><mark>What is Data Structure?</mark>
<br>A data structure is defined as a particular way of storing and organizing data in our devices to use the data efficiently and effectively. The main idea behind using data structures is to minimize the time and space complexities. An efficient data structure takes minimum memory space and requires minimum time to execute the data.<br>

<br><mark>What is Algorithm?</mark>
Algorithm is defined as a process or set of well-defined instructions that are typically used to solve a particular group of problems or perform a specific type of calculation. To explain in simpler terms, it is a set of operations performed in a step-by-step manner to execute a task.<br>How to start learning DSA?
The first and foremost thing is dividing the total procedure into little pieces which need to be done sequentially. The complete process to learn DSA from scratch can be broken into 4 parts:

<br>1.Learn about Time and Space complexities
<br>2.Learn the basics of individual Data Structures
<br>3.Learn the basics of Algorithms
<br>4.Practice Problems on DSA<br><br>1. Learn about Complexities
<br>Here comes one of the interesting and important topics. The primary motive to use DSA is to solve a problem effectively and efficiently. How can you decide if a program written by you is efficient or not? This is measured by complexities. Complexity is of two types:

<br>1.Time Complexity: Time complexity is used to measure the amount of time required to execute the code.
<br>2.Space Complexity: Space complexity means the amount of space required to execute successfully the functionalities of the code. 
<br>3.You will also come across the term Auxiliary Space very commonly in DSA, which refers to the extra space used in the program other than the input data structure.
<br>4.Both of the above complexities are measured with respect to the input parameters.<br><br> But here arises a problem. The time required for executing a code depends on several factors, such as: <br>->The number of operations performed in the program, 
<br>->The speed of the device, and also 
<br>->The speed of data transfer if being executed on an online platform<br><br>It neglects the system-dependent constants and is related to only the number of modular operations being performed in the whole program. The following 3 asymptotic notations are mostly used to represent the time complexity of algorithms:

<br>->Big-O Notation (Ο) – Big-O notation specifically describes the worst-case scenario.
<br>->Omega Notation (Ω) – Omega(Ω) notation specifically describes the best-case scenario.
<br>->Theta Notation (θ) – This notation represents the average complexity of an algorithm.<br><br>2. Learn Data Structures
Here comes the most crucial and the most awaited stage of the roadmap for learning data structure and algorithm – the stage where you start learning about DSA. The topic of DSA consists of two parts: 

Data Structures
Algorithms 
Though they are two different things, they are highly interrelated, and it is very important to follow the right track to learn them most efficiently. If you are confused about which one to learn first, we recommend you to go through our detailed analysis on the topic: What should I learn first- Data Structures or Algorithms?

Here we have followed the flow of learning a data structure and then the most related and important algorithms used by that data structure.<br><br><mark>1. Array</mark>
<br>The most basic yet important data structure is the array. It is a linear data structure. An array is a collection of homogeneous data types where the elements are allocated contiguous memory. Because of the contiguous allocation of memory, any element of an array can be accessed in constant time. Each array element has a corresponding index number.<br>

<br><mark>2. String Data Structure</mark>
<br>A string is also a type of array. It can be interpreted as an array of characters. But it has some special characteristics like the last character of a string is a null character to denote the end of the string. Also, there are some unique operations, like concatenation which concatenates two strings into one.<br><mark>3. Linked Lists</mark>
As the above data structures, the linked list is also a linear data structure. But Linked List is different from Array in its configuration. It is not allocated to contiguous memory locations. Instead, each node of the linked list is allocated to some random memory space and the previous node maintains a pointer that points to this node. So no direct memory access of any node is possible and it is also dynamic i.e., the size of the linked list can be adjusted at any time. To learn more about linked lists refer to the article “Introduction to Linked List“.<br><br><mark>4. Matrix/Grid</mark>
A matrix represents a collection of numbers arranged in an order of rows and columns. It is necessary to enclose the elements of a matrix in parentheses or brackets.For example:A matrix with 9 elements is shown below.<br>This is the primary technique mentioned in the two sorting algorithms Merge Sort and Quick Sort which are mentioned earlier. To learn more about the technique, the cases where it is used, and its implementation and solve some interesting problems, please refer to the dedicated article Divide and Conquer Algorithm.<br>

<br><mark>4. Greedy Algorithms</mark>
As the name suggests, this algorithm builds up the solution one piece at a time and chooses the next piece which gives the most obvious and immediate benefit i.e., which is the most optimal choice at that moment. So the problems where choosing locally optimal also leads to the global solutions are best fit for Greedy.

For example, consider the Fractional Knapsack Problem. The local optimal strategy is to choose the item that has maximum value vs weight ratio. This strategy also leads to a globally optimal solution because we are allowed to take fractions of an item.</h3>
    </body>
</head>
</html>